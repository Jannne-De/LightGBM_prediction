{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86259,"databundleVersionId":9778966,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install vaderSentiment\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T08:04:06.774454Z","iopub.execute_input":"2024-10-24T08:04:06.774856Z","iopub.status.idle":"2024-10-24T08:04:19.425952Z","shell.execute_reply.started":"2024-10-24T08:04:06.774817Z","shell.execute_reply":"2024-10-24T08:04:19.424859Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting vaderSentiment\n  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vaderSentiment) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (2024.8.30)\nDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: vaderSentiment\nSuccessfully installed vaderSentiment-3.3.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom PIL import Image, ImageStat\nimport os\nimport re\nimport emoji\nfrom imblearn.over_sampling import SMOTE\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.models import Model\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\n# Шляхи до файлів\nprint(\"Завантаження шляхів до файлів...\")\nTRAIN_CSV = '/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-10/train.csv'\nTEST_CSV = '/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-10/test.csv'\nTRAIN_IMAGES_PATH = '/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-10/images/images/train'\nTEST_IMAGES_PATH = '/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-10/images/images/test'\n\n# Завантаження даних\nprint(\"Завантаження даних...\")\ntrain_data = pd.read_csv(TRAIN_CSV)\ntest_data = pd.read_csv(TEST_CSV)\nprint(\"Розмір тренувального набору:\", train_data.shape)\nprint(\"Розмір тестового набору:\", test_data.shape)\n\n# Заповнення пропущених значень у колонці 'Description' і конвертація в рядки\ntrain_data['Description'] = train_data['Description'].fillna('').astype(str)\ntest_data['Description'] = test_data['Description'].fillna('').astype(str)\n\n\n# Функція для обчислення середньої яскравості зображення\ndef calculate_brightness(image_path):\n    try:\n        img = Image.open(image_path).convert('L')  # Конвертація в чорно-біле зображення\n        stat = ImageStat.Stat(img)\n        return stat.mean[0]  # Середня яскравість\n    except:\n        return 0\n\n\n# Функція для обробки зображення через ResNet50\ndef process_image(image_path):\n    try:\n        img = image.load_img(image_path, target_size=(224, 224))\n        img_data = image.img_to_array(img)\n        img_data = np.expand_dims(img_data, axis=0)\n        img_data = preprocess_input(img_data)\n        return img_data\n    except:\n        return np.zeros((224, 224, 3))\n\n\n# Завантаження ResNet50 для отримання ознак\nbase_model = ResNet50(weights='imagenet', include_top=False)\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nmodel = Model(inputs=base_model.input, outputs=x)\n\n\n# Функція для витягнення ознак зображень через ResNet50\ndef extract_image_features_resnet(pet_id, path):\n    img_folder = f'{path}/{pet_id}'\n    if not os.path.exists(img_folder):\n        return np.zeros((2048,))  # Якщо немає зображень\n\n    image_files = os.listdir(img_folder)\n    if len(image_files) == 0:\n        return np.zeros((2048,))\n\n    # Обробляємо перше зображення\n    img_path = f'{img_folder}/{image_files[0]}'\n    img_data = process_image(img_path)\n    features = model.predict(img_data)\n\n    return features.flatten()\n\n\n# Створюємо метаінформацію для тренувальних даних\nprint(\"Обробка зображень для метаінформації через ResNet50...\")\ntrain_data['image_features'] = train_data['PetID'].apply(lambda x: extract_image_features_resnet(x, TRAIN_IMAGES_PATH))\n\n# Створюємо метаінформацію для тестових даних\nprint(\"Обробка тестових зображень для метаінформації через ResNet50...\")\ntest_data['image_features'] = test_data['PetID'].apply(lambda x: extract_image_features_resnet(x, TEST_IMAGES_PATH))\n\n\n# Функція для виділення віку\ndef extract_age(description):\n    age_search = re.search(r'\\b\\d{1,2}\\s?(months?|years?)\\b', description.lower())\n    if age_search:\n        age = age_search.group(0)\n        # Конвертація віку в місяці або роки\n        if 'year' in age:\n            return int(re.search(r'\\d+', age).group(0)) * 12  # Конвертуємо в місяці\n        elif 'month' in age:\n            return int(re.search(r'\\d+', age).group(0))  # Залишаємо в місяцях\n    return np.nan\n\n\n# Функція для виділення породи (тільки наявність або відсутність згадки про породу)\ndef extract_breed_presence(description):\n    breed_search = re.search(r'\\b(mixed breed|poodle|labrador|bulldog|cat|dog)\\b', description.lower())\n    return 1 if breed_search else 0\n\n\n# Функція для виділення стану здоров'я\ndef extract_health_status(description):\n    health_search = re.search(r'\\b(healthy|vaccinated|neutered|sick)\\b', description.lower())\n    if health_search:\n        return health_search.group(0)\n    return 'unknown'\n\n\n# Функція для підрахунку кількості емодзі в тексті\ndef count_emojis(text):\n    return len([char for char in text if char in emoji.EMOJI_DATA])\n\n\n# Аналіз емоційного забарвлення тексту за допомогою VADER\nanalyzer = SentimentIntensityAnalyzer()\n\n\ndef extract_sentiment(description):\n    sentiment = analyzer.polarity_scores(description)\n    return pd.Series([sentiment['pos'], sentiment['neu'], sentiment['neg'], sentiment['compound']])\n\n\n# Додаємо нові ознаки до датасету\ntrain_data['Age'] = train_data['Description'].apply(extract_age)\ntrain_data['Breed_Presence'] = train_data['Description'].apply(extract_breed_presence)\ntrain_data['Health_Status'] = train_data['Description'].apply(extract_health_status)\ntrain_data['emoji_count'] = train_data['Description'].apply(count_emojis)\n\ntest_data['Age'] = test_data['Description'].apply(extract_age)\ntest_data['Breed_Presence'] = test_data['Description'].apply(extract_breed_presence)\ntest_data['Health_Status'] = test_data['Description'].apply(extract_health_status)\ntest_data['emoji_count'] = test_data['Description'].apply(count_emojis)\n\n# Додаємо ознаки емоційного забарвлення (позитивний, нейтральний, негативний, комбінований)\ntrain_data[['sentiment_pos', 'sentiment_neu', 'sentiment_neg', 'sentiment_compound']] = train_data['Description'].apply(\n    extract_sentiment)\ntest_data[['sentiment_pos', 'sentiment_neu', 'sentiment_neg', 'sentiment_compound']] = test_data['Description'].apply(\n    extract_sentiment)\n\n# Додаємо бінарну ознаку для відсутності віку\ntrain_data['Age_missing'] = train_data['Age'].isna().astype(int)\ntest_data['Age_missing'] = test_data['Age'].isna().astype(int)\n\n# Замінюємо пропущені значення в Age спеціальним кодом (-1 для позначення невідомого віку)\ntrain_data['Age'] = train_data['Age'].fillna(-1)\ntest_data['Age'] = test_data['Age'].fillna(-1)\n\n# Обробка тексту за допомогою TF-IDF\nvectorizer = TfidfVectorizer(max_features=5000)\ntrain_text_data = vectorizer.fit_transform(train_data['Description'].fillna(''))\ntest_text_data = vectorizer.transform(test_data['Description'].fillna(''))\n\n# Підготовка повного набору ознак\ntrain_features = np.hstack([\n    train_text_data.toarray(),\n    np.vstack(train_data['image_features'].values),\n    train_data[['Breed_Presence', 'Age', 'emoji_count', 'Age_missing',\n                'sentiment_pos', 'sentiment_neu', 'sentiment_neg', 'sentiment_compound']].values\n])\n\ntest_features = np.hstack([\n    test_text_data.toarray(),\n    np.vstack(test_data['image_features'].values),\n    test_data[['Breed_Presence', 'Age', 'emoji_count', 'Age_missing',\n               'sentiment_pos', 'sentiment_neu', 'sentiment_neg', 'sentiment_compound']].values\n])\n\n# Стандартизація даних\nscaler = StandardScaler()\ntrain_features_scaled = scaler.fit_transform(train_features)\ntest_features_scaled = scaler.transform(test_features)\n\n# Розділення на тренувальні та валідаційні набори\nX_train, X_val, y_train, y_val = train_test_split(train_features_scaled, train_data['AdoptionSpeed'], test_size=0.2,\n                                                  random_state=42)\n\n# Балансування класів за допомогою SMOTE (якщо потрібно)\nprint(\"Балансування класів за допомогою SMOTE...\")\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n\n# Обчислення ваг класів\nprint(\"Обчислення ваг класів...\")\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(enumerate(class_weights))\n\n# Тренування моделі LightGBM\nlgb_model = lgb.LGBMRegressor(objective='regression', metric='rmse', num_leaves=31, learning_rate=0.05,\n                              n_estimators=5000)\n\nprint(\"Тренування моделі LightGBM...\")\nlgb_model.fit(X_train_balanced, y_train_balanced)\n\n# Прогнозування на валідаційних даних\ny_val_pred = lgb_model.predict(X_val)\ny_val_pred_rounded = np.round(y_val_pred).astype(int)\ny_val_pred_rounded = np.clip(y_val_pred_rounded, 1, 4)\n\n# Оцінка метрики Kappa на валідаційних даних\nkappa = cohen_kappa_score(y_val, y_val_pred_rounded, weights='quadratic')\nprint(\"Quadratic Weighted Kappa на валідаційних даних:\", kappa)\n\n# Прогнозування на тестових даних\nprint(\"Прогнозування на тестових даних...\")\npredictions = lgb_model.predict(test_features_scaled)\npredictions_rounded = np.round(predictions).astype(int)\npredictions_rounded = np.clip(predictions_rounded, 1, 4)\n\n# Формування файлу submission.csv\nsubmission = pd.DataFrame({'PetID': test_data['PetID'], 'AdoptionSpeed': predictions_rounded})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Файл submission.csv сформовано.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T08:13:18.216638Z","iopub.execute_input":"2024-10-24T08:13:18.217108Z","iopub.status.idle":"2024-10-24T08:16:01.896503Z","shell.execute_reply.started":"2024-10-24T08:13:18.217061Z","shell.execute_reply":"2024-10-24T08:16:01.895301Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Завантаження шляхів до файлів...\nЗавантаження даних...\nРозмір тренувального набору: (6431, 3)\nРозмір тестового набору: (1891, 2)\nОбробка зображень для метаінформації через ResNet50...\nОбробка тестових зображень для метаінформації через ResNet50...\nБалансування класів за допомогою SMOTE...\nОбчислення ваг класів...\nТренування моделі LightGBM...\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104040 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 79343\n[LightGBM] [Info] Number of data points in the train set: 6804, number of used features: 1709\n[LightGBM] [Info] Start training from score 2.500000\nQuadratic Weighted Kappa на валідаційних даних: 0.3196684195591404\nПрогнозування на тестових даних...\nФайл submission.csv сформовано.\n","output_type":"stream"}]}]}